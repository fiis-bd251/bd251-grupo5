## 7.3. Carga Masiva de Datos

Con el objetivo de poblar eficientemente las tablas del sistema log√≠stico del √°rea de transporte de San Fernando, se implement√≥ una estrategia de carga masiva utilizando archivos `.csv` generados autom√°ticamente con herramientas como ChatGPT, Mockaroo y scripts personalizados.

### üõ†Ô∏è Herramientas Utilizadas

- PostgreSQL 14 (utilizando pgAdmin, DBeaver o CLI)
- Generaci√≥n de datos con Python o Mockaroo
- Archivos `.csv` estructurados y validados manualmente
- Carpeta compartida de datos con acceso interno ([Ver carpeta de datos](./datos/))

### üì• Proceso de Carga

1. **Generaci√≥n de Datos**
   - Se generaron archivos `.csv` con miles de registros, basados en las proyecciones anuales de crecimiento de la base de datos.
   - Los datos simulados respetaron las claves primarias, for√°neas y restricciones definidas en el dise√±o del modelo.

2. **Importaci√≥n a PostgreSQL**
   - A trav√©s de herramientas como pgAdmin:
     - Click derecho sobre la tabla ‚Üí *Import/Export*.
     - Selecci√≥n del archivo `.csv` (UTF-8).
     - Uso de delimitador coma `,`.
     - Activaci√≥n del encabezado si el archivo lo conten√≠a.
     - Verificaci√≥n del orden correcto de columnas seg√∫n la tabla.

3. **Validaci√≥n**
   - Se realizaron consultas de conteo (`SELECT COUNT(*)`) tras la carga para verificar el n√∫mero de registros.
   - Se comprob√≥ la integridad referencial entre tablas relacionadas.
   - Se validaron tipos de datos y restricciones de dominio.

### ‚ö†Ô∏è Consideraciones

- Todos los archivos `.csv` fueron codificados en UTF-8 para evitar errores con tildes o caracteres especiales.
- Se respet√≥ el orden de carga:
  1. Tablas de referencia (estados, tipos, cat√°logos)
  2. Tablas relacionales o intermedias
  3. Tablas transaccionales (registros de operaci√≥n)
- La carga masiva se realiz√≥ en un entorno de pruebas antes de aplicar en producci√≥n para garantizar integridad y consistencia.
